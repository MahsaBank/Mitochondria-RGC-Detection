This repository contains the code for training an RGC detector model (train.py script) and predicting mitochondria (inference.py) in RGC boutons within an EM volume using the trained detector. The RGC detector is a U-Net++ model with a ResNet-34 encoder, designed to predict the probability of each pixel belonging to an RGC mitochondrion. These probabilities can be thresholded to obtain segmented RGC mitochondria. Finally, the segmented 3D mitochondria can be rendered using the "predictionsToVastSubs.py" script. The voxel locations of the segments are stored in the "vastSubs" list. Each element in "vastSubs" contains the x, y, and z coordinates of a 3D RGC mitochondrion object. 

There may be some misalignment between planes, which can cause issues during 3D rendering. You can use the "calculateTranslationsOfVastSubsAcrossAdjacentSlices.py" script to calculate the translation matrix between adjacent planes. The matrix is saved in the "shiftZ" list, which can then be used to translate the detected mitochondria segments across adjacent planes. You can find snapshots of the segments in the "test_results" folder within this repository.

The dataset is stored in Zarr format with two key names: "raw" and "pred". The EM stack is organized into plane folders, with each plane folder containing diced patches of raw images arranged in a "row_col" structure. Each patch is a 512 Ã— 512 array. After running inference.py, the predictions are saved under the "pred" entry in the Zarr file.


